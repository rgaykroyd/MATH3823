<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MATH3823 Generalized Linear Models - 3&nbsp; GLM Theory</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./4_GLM-Fitting.html" rel="next">
<link href="./2_linearmodels.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GLM Theory</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MATH3823 Generalized Linear Models</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_linearmodels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Essentials of Gaussian Linear Models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_GLM-Theory.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GLM Theory</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4_GLM-Fitting.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">GLM fitting</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5_logisticmodel.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Logistic regression model</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6_loglinearmodel.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Loglinear models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7_extendedloglinearmodel.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Extensions to Loglinear models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8_summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Appendix: Background to analysis of variance</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./revision.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">A: Revision of vectors and matrices</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./formula-sheet.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Appendix: Standard distributions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#motivating-examples" id="toc-motivating-examples" class="nav-link active" data-scroll-target="#motivating-examples"><span class="toc-section-number">3.1</span>  Motivating examples</a></li>
  <li><a href="#the-glm-structure" id="toc-the-glm-structure" class="nav-link" data-scroll-target="#the-glm-structure"><span class="toc-section-number">3.2</span>  The GLM structure</a></li>
  <li><a href="#the-random-part-of-a-glm" id="toc-the-random-part-of-a-glm" class="nav-link" data-scroll-target="#the-random-part-of-a-glm"><span class="toc-section-number">3.3</span>  The random part of a GLM</a>
  <ul class="collapse">
  <li><a href="#example-poisson-distribution" id="toc-example-poisson-distribution" class="nav-link" data-scroll-target="#example-poisson-distribution"><span class="toc-section-number">3.3.1</span>  Example: Poisson distribution</a></li>
  <li><a href="#sec-exponential-binomial" id="toc-sec-exponential-binomial" class="nav-link" data-scroll-target="#sec-exponential-binomial"><span class="toc-section-number">3.3.2</span>  Example: Binomial distribution</a></li>
  <li><a href="#example-normal-distribution" id="toc-example-normal-distribution" class="nav-link" data-scroll-target="#example-normal-distribution"><span class="toc-section-number">3.3.3</span>  Example: Normal distribution</a></li>
  </ul></li>
  <li><a href="#sec-exponential-family" id="toc-sec-exponential-family" class="nav-link" data-scroll-target="#sec-exponential-family"><span class="toc-section-number">3.4</span>  Moments of exponential-family distributions</a></li>
  <li><a href="#the-systematic-part-of-the-model" id="toc-the-systematic-part-of-the-model" class="nav-link" data-scroll-target="#the-systematic-part-of-the-model"><span class="toc-section-number">3.5</span>  The systematic part of the model</a></li>
  <li><a href="#the-link-function" id="toc-the-link-function" class="nav-link" data-scroll-target="#the-link-function"><span class="toc-section-number">3.6</span>  The link function</a></li>
  <li><a href="#the-canonical-links" id="toc-the-canonical-links" class="nav-link" data-scroll-target="#the-canonical-links"><span class="toc-section-number">3.7</span>  The canonical links</a>
  <ul class="collapse">
  <li><a href="#example-canonical-link-function-for-poisson-distribution" id="toc-example-canonical-link-function-for-poisson-distribution" class="nav-link" data-scroll-target="#example-canonical-link-function-for-poisson-distribution"><span class="toc-section-number">3.7.1</span>  Example: canonical link function for Poisson distribution</a></li>
  <li><a href="#example-canonical-link-function-for-normal-distribution" id="toc-example-canonical-link-function-for-normal-distribution" class="nav-link" data-scroll-target="#example-canonical-link-function-for-normal-distribution"><span class="toc-section-number">3.7.2</span>  Example: canonical link function for Normal distribution</a></li>
  <li><a href="#range-of-canonical-link-functions" id="toc-range-of-canonical-link-functions" class="nav-link" data-scroll-target="#range-of-canonical-link-functions"><span class="toc-section-number">3.7.3</span>  Range of canonical link functions</a></li>
  <li><a href="#sec-canonicallinkconvenience" id="toc-sec-canonicallinkconvenience" class="nav-link" data-scroll-target="#sec-canonicallinkconvenience"><span class="toc-section-number">3.7.4</span>  Convenience of the canonical link function</a></li>
  </ul></li>
  <li><a href="#sec-mle" id="toc-sec-mle" class="nav-link" data-scroll-target="#sec-mle"><span class="toc-section-number">3.8</span>  Maximum likelihood estimation for generalized linear models</a>
  <ul class="collapse">
  <li><a href="#sec-mle.iid" id="toc-sec-mle.iid" class="nav-link" data-scroll-target="#sec-mle.iid"><span class="toc-section-number">3.8.1</span>  The i.i.d. case</a></li>
  <li><a href="#accuracy-of-mles-in-the-i.i.d.-case" id="toc-accuracy-of-mles-in-the-i.i.d.-case" class="nav-link" data-scroll-target="#accuracy-of-mles-in-the-i.i.d.-case"><span class="toc-section-number">3.8.2</span>  Accuracy of MLEs in the i.i.d. case</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="toc-section-number">3.9</span>  Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GLM Theory</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<div class="hidden">
<p><span class="math display">\[
\def\b#1{\mathbf{#1}}
\def\E{\mbox{E}}
\def\V{\mbox{Var}}
\]</span></p>
</div>
<section id="motivating-examples" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="motivating-examples"><span class="header-section-number">3.1</span> Motivating examples</h2>
<p>We cannot always assume that the dependent variable <span class="math inline">\(y\)</span> is normally distributed. For example, for the beetle mortality data in <a href="1_intro.html#tbl-beetle-data">Table&nbsp;<span>1.1</span></a>, suppose each beetle subjected to a dose <span class="math inline">\(x_i\)</span> has a probability <span class="math inline">\(p_i\)</span> of being killed. Then the number of beetles killed <span class="math inline">\(y_i\)</span> out of a total number <span class="math inline">\(m_i\)</span> at dose-level <span class="math inline">\(x_i\)</span> will have a <span class="math inline">\(\text{Bin}(m_i,p_i)\)</span> distribution:</p>
<p><span id="eq-GLM-Binomial"><span class="math display">\[
\text{Pr}(y_i ;~ p_i,m_i) = \left(\begin{array}{c} m_i\\ y_i \end{array} \right) p_i^{y_i} (1-p_i)^{m_i-y_i}
\tag{3.1}\]</span></span> where <span class="math inline">\(y_i\)</span> takes values in <span class="math inline">\(\{0,1,\dots,m_i\}\)</span>.</p>
<p><a href="#tbl-cyclone-data">Table&nbsp;<span>3.1</span></a> contains seasonal data on tropical cyclones for 13 seasons. Suppose that, within season <span class="math inline">\(i\)</span>, there is a constant probability <span class="math inline">\(\lambda_i dt\)</span> of a cyclone occurring in any short time-interval <span class="math inline">\(dt\)</span>. Then the total number of cyclones <span class="math inline">\(y_i\)</span> during season <span class="math inline">\(i\)</span> will have a Poisson distribution with mean <span class="math inline">\(\lambda_i\)</span>, that is <span class="math inline">\(y_i\sim \text{Po}(\lambda_i)\)</span>:</p>
<p><span id="eq-GLM-Poisson"><span class="math display">\[
\text{Pr}(y_i ;~ \lambda_i) = \frac{\lambda_i^{y_i} e^{-\lambda_i} }{y_i!}
\tag{3.2}\]</span></span> where <span class="math inline">\(y_i\)</span> takes values in <span class="math inline">\(\{0,1,2,\dots\}\)</span>.</p>
<div id="tbl-cyclone-data" class="anchored">
<table class="table">
<caption>Table&nbsp;3.1: Numbers of tropical cyclones in <span class="math inline">\(n = 13\)</span> successive seasons<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></caption>
<colgroup>
<col style="width: 19%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
</colgroup>
<tbody>
<tr class="odd">
<td>Season</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">13</td>
</tr>
<tr class="even">
<td>No of cyclones</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">4</td>
</tr>
</tbody>
</table>
</div>
<p>In these two examples, we have non-normal data and would like to know whether and how the dependent variable <span class="math inline">\(y_i\)</span> depends on the covariate <span class="math inline">\(x_i\)</span> or <span class="math inline">\(i\)</span>.</p>
<p>Generalized linear models provide a modelling framework for data analysis in the non-normal setting. We will revisit the beetle mortality and cyclone data sets after describing the structure of a generalized linear model.</p>
</section>
<section id="the-glm-structure" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="the-glm-structure"><span class="header-section-number">3.2</span> The GLM structure</h2>
<p>A <em>generalized linear model</em> relates a continuous or discrete response variable <span class="math inline">\(y\)</span> to a set of explanatory variables <span class="math inline">\(x=(x_1, \ldots, x_p)\)</span>. The model contains three parts:</p>
<p><strong>Random part:</strong> The probability function of <span class="math inline">\(y\)</span> is assumed to belong to the <em>two-parameter</em> <em>exponential family</em> of distributions with parameters <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span>:</p>
<p><span id="eq-exponential-family"><span class="math display">\[
f(y; \theta, \phi) = \exp \left\{ \frac{y \theta - b(\theta)}
                  {\phi} + c(y, \phi) \right\},
\tag{3.3}\]</span></span> where <span class="math inline">\(\phi&gt;0\)</span>. Here, <span class="math inline">\(\theta\)</span> is called the <em>canonical</em> or <em>natural</em> parameter of the distribution and <span class="math inline">\(\phi\)</span> is called the <em>scale</em> parameter. We show below that the mean <span class="math inline">\(\mbox{E}[y]\)</span> depends only on <span class="math inline">\(\theta\)</span>, and <span class="math inline">\(\mbox{Var}[y]\)</span> depends on <span class="math inline">\(\phi\)</span> and possibly also <span class="math inline">\(\theta\)</span>. Various choices for functions <span class="math inline">\(b(\cdot)\)</span> and <span class="math inline">\(c(\cdot)\)</span> produce a wide variety of familiar distributions (see below). Sometimes we may set <span class="math inline">\(\phi=1\)</span>; then <a href="#eq-exponential-family">Equation&nbsp;<span>3.3</span></a> is called the <em>one-parameter exponential family</em>.</p>
<p>Further, note that in some references to generalized linear models (such as Dobson and Barnett, 3rd edn.), <span class="math inline">\(\phi\)</span> does not appear at all in the exponential family formula <a href="#eq-exponential-family">Equation&nbsp;<span>3.3</span></a>, instead it is absorbed into <span class="math inline">\(\theta\)</span> and <span class="math inline">\(b(\theta)\)</span>.</p>
<p>In this module, we will generally assume that each observation <span class="math inline">\(y_i\)</span>, <span class="math inline">\(i=1,\dots,n\)</span>, is <em>independently</em> drawn from an exponential family where <span class="math inline">\(\theta\)</span> depends on the covariates for each unit of observation <span class="math inline">\(i\)</span>. Thus we write <span class="math display">\[
f(y_i; \theta_i, \phi) = \exp \left\{ \frac{y_i \theta_i - b(\theta_i)}   {\phi} + c(y_i, \phi) \right\}.
\]</span> Note the subscripts on both <span class="math inline">\(y\)</span> and <span class="math inline">\(\theta\)</span>.</p>
<p><strong>Systematic part:</strong> This is a <em>linear predictor</em>: <span id="eq-linpred"><span class="math display">\[
\eta = \sum_{j=1}^p \beta_j x_j.
\tag{3.4}\]</span></span></p>
<p><strong>Link function:</strong> This is an isomorphic function providing the link between the linear predictor <span class="math inline">\(\eta\)</span> and the mean <span class="math inline">\(\mu = \mbox{E}[y]\)</span>:</p>
<p><span id="eq-link-functions"><span class="math display">\[
\eta = g(\mu), \quad \mbox{and} \quad \mu  = g^{-1}(\eta) = h(\eta).
\tag{3.5}\]</span></span></p>
<p>Here, <span class="math inline">\(g(\mu)\)</span> is called the <em>link function</em>, and <span class="math inline">\(h(\eta)\)</span> is called the <em>inverse link function</em>.</p>
<p>We will now discuss each of these parts in more detail.</p>
</section>
<section id="the-random-part-of-a-glm" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="the-random-part-of-a-glm"><span class="header-section-number">3.3</span> The random part of a GLM</h2>
<p>We begin with some examples of exponential family members.</p>
<section id="example-poisson-distribution" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="example-poisson-distribution"><span class="header-section-number">3.3.1</span> Example: Poisson distribution</h3>
<p>If <span class="math inline">\(y\)</span> has a Poisson distribution with parameter <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(y \sim \text{Po}(\lambda)\)</span>, then <span class="math inline">\(y\)</span> takes values in <span class="math inline">\(\{0,1,2,\dots\}\)</span> and has probability mass function: <span id="eq-poisson-expanded"><span class="math display">\[
f(y) = \frac{e^{-\lambda} \lambda^y} {y!}  
     = \exp \left\{y \log \lambda - \lambda - \log y! \right\},
\tag{3.6}\]</span></span> which has the form of <a href="#eq-exponential-family">Equation&nbsp;<span>3.3</span></a> with components as in <a href="#tbl-GLM-poisson">Table&nbsp;<span>3.2</span></a>.</p>
<div id="tbl-GLM-poisson" class="anchored">
<table class="table">
<caption>Table&nbsp;3.2: Exponential model components for the Poisson</caption>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(\theta\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\phi\)</span></th>
<th style="text-align: center;"><span class="math inline">\(b(\theta)\)</span></th>
<th style="text-align: center;"><span class="math inline">\(c(y,\phi)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\log\lambda\)</span></td>
<td style="text-align: center;"><span class="math inline">\(1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\lambda=e^\theta\)</span></td>
<td style="text-align: center;"><span class="math inline">\(-\log y!\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>For example, to model the cyclones data in <a href="#tbl-cyclone-data">Table&nbsp;<span>3.1</span></a>, we might simply assume that the number of cyclones in each season has a Poisson distribution, assuming a constant rate <span class="math inline">\(\lambda\)</span> across all seasons <span class="math inline">\(i\)</span>. That is <span class="math inline">\(y_i \sim \text{Po}(\lambda).\)</span></p>
</section>
<section id="sec-exponential-binomial" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="sec-exponential-binomial"><span class="header-section-number">3.3.2</span> Example: Binomial distribution</h3>
<p>Let <span class="math inline">\(y\)</span> have a Binomial distribution, (write <span class="math inline">\(y \sim \text{Bin}(m, p)\)</span> with <span class="math inline">\(m\)</span> fixed. Then <span class="math inline">\(y\)</span> is discrete, taking values in <span class="math inline">\(\{0,1,\dots,m\}\)</span>, and has probability mass{#tbl-GLM-poisson} function: <span class="math display">\[
f(y) = {m \choose y} p^y (1 - p)^{m - y} = {m \choose y} \left(\frac{p}{1-p} \right)^y (1 - p)^m
\]</span> which can be re-written as <span id="eq-GLM-Binomial-form"><span class="math display">\[
f(y)  = \exp \left\{ y\ \mbox{logit } p  + m \log (1-p) + \log {m \choose y}\right\},
\tag{3.7}\]</span></span> which has the form of <a href="#eq-exponential-family">Equation&nbsp;<span>3.3</span></a> with, <span class="math display">\[
\theta=\text{logit} \ p = \log \left( \frac{p}{1-p}\right),
\]</span> and with components as in <a href="#tbl-GLM-binomial">Table&nbsp;<span>3.3</span></a>.</p>
<div id="tbl-GLM-binomial" class="anchored">
<table class="table">
<caption>Table&nbsp;3.3: Exponential model components for the Binomial</caption>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(\theta\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\phi\)</span></th>
<th style="text-align: center;"><span class="math inline">\(b(\theta)\)</span></th>
<th style="text-align: center;"><span class="math inline">\(c(y,\phi)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\mbox{logit }p\)</span></td>
<td style="text-align: center;"><span class="math inline">\(1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(m\log(1+e^\theta)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\log{m\choose y}\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>Where it can be shown that <span class="math inline">\(-m\log(1-p)=m\log(1+e^\theta)\)</span> – see Exercises.</p>
</section>
<section id="example-normal-distribution" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="example-normal-distribution"><span class="header-section-number">3.3.3</span> Example: Normal distribution</h3>
<p>Let <span class="math inline">\(y\)</span> have a Normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Then <span class="math inline">\(y\)</span> takes values on the whole real line and has probability density function</p>
<p><span class="math display">\[\begin{align*}
f(y; \mu, \sigma^2) &amp;= \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left\{ \frac{-1}{2\sigma^2} (y - \mu)^2 \right\}, \notag \\
                    &amp;= \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left\{-\frac{y^2}{2 \sigma^2} + \frac{y\mu}{\sigma^2} - \frac{\mu^2}{2 \sigma^2}\right\}\\
                    &amp;= \exp \left\{ \frac{y \mu - \mu^2/2}{\sigma^2} + \left[\frac{-y^2}{2\sigma^2} - \frac{1}{2} \log (2 \pi \sigma^2)
                              \right]\right\},
\end{align*}\]</span> which has the form of <a href="#eq-exponential-family">Equation&nbsp;<span>3.3</span></a> with components as in <a href="#tbl-GLM-gaussian">Table&nbsp;<span>3.4</span></a>.</p>
<div id="tbl-GLM-gaussian" class="anchored">
<table class="table">
<caption>Table&nbsp;3.4: Exponential model components for the Gaussian</caption>
<colgroup>
<col style="width: 21%">
<col style="width: 21%">
<col style="width: 21%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(\theta\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\phi\)</span></th>
<th style="text-align: center;"><span class="math inline">\(b(\theta)\)</span></th>
<th style="text-align: center;"><span class="math inline">\(c(y,\phi)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\mu\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\sigma^2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\theta^2/2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(-\frac{y^2}{2\phi} - \frac{1}{2} \log (2 \pi \phi)\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>Where it can be shown that <span class="math inline">\(\frac{-y^2}{2\sigma^2} - \frac{1}{2} \log (2 \pi \sigma^2)=-\frac{y^2}{2\phi} - \frac{1}{2} \log (2 \pi \phi)\)</span> – see Exercises.</p>
<p>From the usual regression point of view, we write <span class="math inline">\(y = \alpha + \beta x + \epsilon\)</span>, with <span class="math inline">\(\epsilon \sim N(0, \sigma^2)\)</span>. From the point of view of a generalized linear model, we write <span class="math inline">\(y \sim N(\mu, \sigma^2)\)</span> where <span class="math inline">\(\mu(x) = \alpha + \beta x\)</span>.</p>
</section>
</section>
<section id="sec-exponential-family" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="sec-exponential-family"><span class="header-section-number">3.4</span> Moments of exponential-family distributions</h2>
<p>It is straightforward to find the mean and variance of <span class="math inline">\(Y\)</span> in terms of <span class="math inline">\(b(\theta)\)</span> and <span class="math inline">\(\phi\)</span>. Since we want to explore the dependence of <span class="math inline">\(\mbox{E}[Y]\)</span> on explanatory variables, this property makes the exponential family very convenient.</p>
<div id="prp-moments" class="proposition theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.1 </strong></span>For random variables in the exponential family: <span id="eq-exponential-moments"><span class="math display">\[
\mbox{E}[Y] = b'(\theta), \quad \mbox{and } \quad \mbox{Var}[Y] =  b''(\theta)\phi.
\tag{3.8}\]</span></span></p>
</div>
<p><strong>Proof</strong> We give the proof for a continuous random variables. For the discrete case, replace all integrals by sums.</p>
<p>Starting with the simple property that all probability density functions integrate to 1, we have <span class="math display">\[
1 = \int \exp \left\{ \frac{y \theta - b(\theta)}{\phi} + c(y,\phi)\right\} dy
\]</span> and then differentiating both sides with respect to <span class="math inline">\(\theta\)</span> gives <span id="eq-prop1"><span class="math display">\[
0 = \int \left[\frac{ y - b'(\theta)}{\phi} \right]\exp \left\{ \frac{y \theta - b(\theta)}{\phi} + c(y,\phi)\right\}\ dy.
\tag{3.9}\]</span></span> Next, using the definition of the exponential family to simplify the equation gives <span class="math display">\[
0 = \int \left[\frac{ y - b'(\theta)}{\phi} \right] f(y; \theta)\ dy
\]</span> and expanding the brackets leads to <span class="math display">\[
0 = \frac{1}{\phi} \left(\int y f(y; \theta) dy - b'(\theta) \int f(y;\theta)\ dy \right).
\]</span> The first integral is simply the expectation of <span class="math inline">\(Y\)</span> and the second is the integral of the probability density function of <span class="math inline">\(Y\)</span>, and hence <span class="math display">\[
0 = \frac{1}{\phi} \left(\mbox{E}[Y] - b'(\theta)\right)
\]</span> which implies that <span id="eq-prop2"><span class="math display">\[
\mbox{E}[Y] = b'(\theta),
\tag{3.10}\]</span></span> which proves the first part of the proposition.</p>
<p>Differentiating <a href="#eq-prop1">Equation&nbsp;<span>3.9</span></a> by parts and then using the definition of the exponential family to simplify again yields <span class="math display">\[
0 = \int \left\{ -\frac{b''(\theta)}{\phi} + \left[\frac{ y - b'(\theta)}{\phi} \right]^2 \right\} f(y; \theta)\ dy
\]</span> and using <a href="#eq-prop2">Equation&nbsp;<span>3.10</span></a> gives, <span class="math display">\[
0  =  -\frac{b''(\theta)}{\phi} +\int \left[\frac{ y - \mbox{E}[Y]}{\phi} \right]^2  f(y; \theta)\ dy
\]</span> <span class="math display">\[
0 = -\frac{b''(\theta)}{\phi} + \frac{\mbox{Var}[Y]}{\phi^2}
\]</span> which implies that <span class="math display">\[
\mbox{Var}[Y] = \phi \ b''(\theta).
\]</span> which proves the second part of the proposition.</p>
<p>Together, these two results allow us to write down the expectation and variance for any random variable once we have shown that it is a member of the exponential family.</p>
<div id="tbl-moments" class="anchored">
<table class="table">
<caption>Table&nbsp;3.5: Summary of moment calculations via exponential family properties</caption>
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;"><span class="math inline">\(\theta\)</span></th>
<th style="text-align: center;"><span class="math inline">\(b(\theta)\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\phi\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\mbox{E}[Y]=b'(\theta)\)</span></th>
<th style="text-align: center;"><span class="math inline">\(b''(\theta)\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\mbox{Var}[Y]=b''(\theta)\phi\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Poisson, <span class="math inline">\(Po(\lambda)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\log \lambda\)</span></td>
<td style="text-align: center;"><span class="math inline">\(e^\theta\)</span></td>
<td style="text-align: center;"><span class="math inline">\(1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(e^\theta=\lambda\)</span></td>
<td style="text-align: center;"><span class="math inline">\(e^\theta\)</span></td>
<td style="text-align: center;"><span class="math inline">\(e^\theta\times 1=\lambda\)</span></td>
</tr>
<tr class="even">
<td>Normal, <span class="math inline">\(N(\mu,\sigma^2)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\mu\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\theta^2/2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\sigma^2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\theta=\mu\)</span></td>
<td style="text-align: center;"><span class="math inline">\(1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(1\times \sigma^2=\sigma^2\)</span></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="the-systematic-part-of-the-model" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="the-systematic-part-of-the-model"><span class="header-section-number">3.5</span> The systematic part of the model</h2>
<p>The second part of the generalized linear model, the linear predictor, is given in as <span class="math inline">\(\eta = \sum_{j=1}^p \beta_j x_j\)</span>, where <span class="math inline">\(x_j\)</span> is the <span class="math inline">\(j\)</span>th explanatory variable (with <span class="math inline">\(x_1=1\)</span> for the intercept). Now, for each observation <span class="math inline">\(y_i,\ i=1,\dots,n\)</span>, the explanatory variables may differ. To make explicit this dependence on <span class="math inline">\(i\)</span>, we write: <span id="eq-GLM-linear"><span class="math display">\[
\eta_i = \sum_{j=1}^p \beta_j x_{ij},
\tag{3.11}\]</span></span> where <span class="math inline">\(x_{ij}\)</span> is the value of the <span class="math inline">\(j\)</span>th explanatory variable on individual <span class="math inline">\(i\)</span> (with <span class="math inline">\(x_{i1}=1\)</span>). Rewriting this in matrix notation: <span id="eq-GLM-linear-matrix"><span class="math display">\[
\eta = X \beta,
\tag{3.12}\]</span></span> where now <span class="math inline">\(\boldsymbol{\eta} = (\eta_1,\dots,\eta_n)\)</span> is a vector of linear predictor variables, <span class="math inline">\(\boldsymbol{\beta} = (\beta_1,\dots,\beta_p)\)</span> is a vector of regression parameters, and <span class="math inline">\(X\)</span> is an <span class="math inline">\(n\times p\)</span> design matrix.</p>
<p>Recall from that we are concerned with two kinds of explanatory variable:</p>
<p>Quantitative — for example, <span class="math inline">\(x_j \in (-\infty, \infty)\)</span> etc.</p>
<p>Qualitative — for example, <span class="math inline">\(x_j \in \{A, B, C\}\)</span> etc.</p>
<p>As discussed in , each quantitative variable is represented in <span class="math inline">\(X\)</span> by an <span class="math inline">\(n \times 1\)</span> column vector. Each qualitative variable, with <span class="math inline">\(k+1\)</span> levels, say, is represented by a dummy <span class="math inline">\(n \times k\)</span> matrix of 0’s and 1’s (one column, usually the first, being dropped to avoid identification problems).</p>
</section>
<section id="the-link-function" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="the-link-function"><span class="header-section-number">3.6</span> The link function</h2>
<p>On we saw that the contribution of randomness to an observation <span class="math inline">\(y\)</span> might be described with a member of the exponential family. We also saw that the systematic part of <span class="math inline">\(y\)</span> might be described using a linear predictor <span class="math inline">\(\eta\)</span> of the explanatory variables. In we introduced the notion of a link function <span class="math inline">\(\eta = g(\mu)\)</span> to link these two parts together, where <span class="math inline">\(\mu\)</span> is the mean of <span class="math inline">\(y\)</span>.</p>
<p>Rarely, the choice of link function <span class="math inline">\(g(\mu)\)</span> is motivated by theory underlying the data at hand. For example, in a dose–response setting, the appropriate model could possibly be motivated by the solution to a set of partial differential equations describing the flow through the body of a dose of a drug.</p>
<p>When there is no compelling underlying substantive theory, we typically choose a link function that will transform a restricted range of the dependent variable onto the whole real line. For example, when observations are measurements they are typically positive, so we have <span class="math inline">\(\mu&gt;0\)</span> and might choose the logarithmic link: <span id="eq-G1"><span class="math display">\[
g(\mu) = \log(\mu).
\tag{3.13}\]</span></span> When observations are binomial counts from <span class="math inline">\(B(m,p), \ 0 &lt; p &lt; 1\)</span>, with mean <span class="math inline">\(\mu = mp\)</span>, we might choose the <em>logit</em> link from <span id="eq-G2"><span class="math display">\[
\eta = g(\mu) = \text{logit}(\mu/m)= \text{logit}(p) = \log\{p/(1-p)\}
\tag{3.14}\]</span></span> or the <em>probit</em> link which is the inverse of the cumulative distribution function of the <span class="math inline">\(N(0,1)\)</span> distribution: <span id="eq-probitlink"><span class="math display">\[
\eta = g(\mu) = \Phi^{-1}(\mu/m) = \Phi^{-1}(p),
\tag{3.15}\]</span></span> or the <em>complementary log-log (cloglog)</em> link: <span id="eq-clogloglink"><span class="math display">\[
\eta = g(\mu) = \log(-\log(1-\mu/m))= \log(-\log(1-p)),
\tag{3.16}\]</span></span> or the <em>cauchit</em> link which is the inverse of the cumulative distribution function of the Cauchy (<span class="math inline">\(t_1\)</span>) distribution: <span id="eq-cauchitlink"><span class="math display">\[
\eta = g(\mu) = \tan(\pi(\mu/m-\tfrac{1}{2})) = \tan(\pi(p-\tfrac{1}{2})).
\tag{3.17}\]</span></span> shows these link functions for proportions fitted to the beetle mortality data. This demonstrates that the logit and probit links are very similar, that the complementary log-log link fits these data slightly better in the extremes, but that the cauchit link fits these data quite poorly in the extremes.</p>
<div id="fig-beetle-links" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-beetle-links-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="3_GLM-Theory_files/figure-html/fig-beetle-links-1.png" class="img-fluid figure-img" data-ref-parent="fig-beetle-links" width="672"></p>
<p></p><figcaption class="figure-caption">(a) Logit link</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-beetle-links-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="3_GLM-Theory_files/figure-html/fig-beetle-links-2.png" class="img-fluid figure-img" data-ref-parent="fig-beetle-links" width="672"></p>
<p></p><figcaption class="figure-caption">(b) Probit link</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-beetle-links-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="3_GLM-Theory_files/figure-html/fig-beetle-links-3.png" class="img-fluid figure-img" data-ref-parent="fig-beetle-links" width="672"></p>
<p></p><figcaption class="figure-caption">(c) cloglog link</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-beetle-links-4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="3_GLM-Theory_files/figure-html/fig-beetle-links-4.png" class="img-fluid figure-img" data-ref-parent="fig-beetle-links" width="672"></p>
<p></p><figcaption class="figure-caption">(d) Cauchit link</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.1: Dose–response curves fitted to the beetle mortality data from Table 1.1 with different choices of link function.</figcaption><p></p>
</figure>
</div>
</section>
<section id="the-canonical-links" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="the-canonical-links"><span class="header-section-number">3.7</span> The canonical links</h2>
<p>A mathematically and computationally convenient choice of link function <span class="math inline">\(g(\mu)\)</span> can be constructed by setting: <span id="eq-G3"><span class="math display">\[
\theta =\eta,
\tag{3.18}\]</span></span> where <span class="math inline">\(\theta\)</span> is the canonical parameter of the exponential family as defined in <a href="#eq-exponential-family">Equation&nbsp;<span>3.3</span></a>. Then, <a href="#eq-exponential-moments">Equation&nbsp;<span>3.8</span></a> shows that the mean <span class="math inline">\(\mu\)</span> is a function of <span class="math inline">\(\theta\)</span>. Therefore, <a href="#eq-G3">Equation&nbsp;<span>3.18</span></a> indirectly provides a link between <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\eta\)</span>. That is, <a href="#eq-G3">Equation&nbsp;<span>3.18</span></a> implicitly defines a link function <span class="math inline">\(\eta=g(\mu)\)</span>.</p>
<p>What is the form of this <span class="math inline">\(g(\cdot)\)</span>?</p>
<p>From <a href="#eq-exponential-moments">Equation&nbsp;<span>3.8</span></a>, <span class="math display">\[
\mu = b'(\theta).
\]</span> So, provided function <span class="math inline">\(b'(\cdot)\)</span> has an inverse <span class="math inline">\((b')^{-1}(\cdot)\)</span>, we may write <span id="eq-dbinv"><span class="math display">\[
\theta = (b')^{-1}(\mu).
\tag{3.19}\]</span></span> Now, from <a href="#eq-link-functions">Equation&nbsp;<span>3.5</span></a>, <span class="math inline">\(g(\mu) = \eta\)</span>, so using <a href="#eq-G3">Equation&nbsp;<span>3.18</span></a>: <span id="eq-canonicallinkfun"><span class="math display">\[
g(\mu) = \theta = (b')^{-1}(\mu),
\tag{3.20}\]</span></span> from <a href="#eq-dbinv">Equation&nbsp;<span>3.19</span></a>. This makes explicit the <span class="math inline">\(g(\mu)\)</span> that is implicitly asserted by <a href="#eq-G3">Equation&nbsp;<span>3.18</span></a>. <a href="#eq-canonicallinkfun">Equation&nbsp;<span>3.20</span></a> is called the <em>canonical</em> link function.</p>
<div id="prp-canonicallinkderiv" class="proposition theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.2 </strong></span>For the canonical link function, <span class="math display">\[
g'(\mu) = 1/b''(\theta).
\]</span></p>
</div>
<p><strong>Proof:</strong> From <a href="#prp-moments">Proposition&nbsp;<span>3.1</span></a>, <span class="math inline">\(\mu = E[Y]=b'(\theta)\)</span>, so <span class="math display">\[
\frac{\text{d} \mu }{\text{d} \theta} = b''(\theta).
\]</span> From <a href="#eq-canonicallinkfun">Equation&nbsp;<span>3.20</span></a>, for the canonical link function, we have <span class="math inline">\(\theta = g(\mu)\)</span>, so <span class="math display">\[
\frac{\text{d} \theta }{ \text{d} \mu} = g'(\mu).
\]</span> Now <span class="math inline">\(\text{d} \theta /\text{d} \mu = \left(\text{d} \mu / \text{d} \theta\right)^{-1}\)</span> and hence <span class="math display">\[
g'(\mu) = 1/b''(\theta).
\]</span> Which proves the proposition.</p>
<section id="example-canonical-link-function-for-poisson-distribution" class="level3" data-number="3.7.1">
<h3 data-number="3.7.1" class="anchored" data-anchor-id="example-canonical-link-function-for-poisson-distribution"><span class="header-section-number">3.7.1</span> Example: canonical link function for Poisson distribution</h3>
<p>For the Poisson distribution <span class="math inline">\(\text{Po}(\lambda)\)</span>, we have from <a href="#tbl-GLM-poisson">Table&nbsp;<span>3.2</span></a> that <span class="math inline">\(b(\theta) = e^\theta\)</span>. Therefore,</p>
<p><span class="math display">\[
b'(\theta) = e^\theta,
\]</span> so the inverse of function <span class="math inline">\(b'(\cdot)\)</span> exists and is the inverse of the exponential function, which is the logarithmic function. Then, applying <a href="#eq-canonicallinkfun">Equation&nbsp;<span>3.20</span></a> <span id="eq-canonicallinkfunpoisson"><span class="math display">\[
g(\mu) = \log(\mu)
\tag{3.21}\]</span></span> Thus the canonical link for the Poisson distribution is <span class="math inline">\(\log\)</span>.</p>
</section>
<section id="example-canonical-link-function-for-normal-distribution" class="level3" data-number="3.7.2">
<h3 data-number="3.7.2" class="anchored" data-anchor-id="example-canonical-link-function-for-normal-distribution"><span class="header-section-number">3.7.2</span> Example: canonical link function for Normal distribution</h3>
<p>For the Normal distribution <span class="math inline">\(N(\mu, \sigma^2)\)</span>, we have from <a href="#tbl-GLM-gaussian">Table&nbsp;<span>3.4</span></a> that <span class="math inline">\(b(\theta) = \theta^2/2\)</span>. Therefore <span class="math display">\[
b'(\theta) = \theta
\]</span> so the inverse of function <span class="math inline">\(b'(\cdot)\)</span> exists and is the inverse of the identity function, which is the identity function. (The identity function is that which maps a value onto itself.) Then, applying <a href="#eq-canonicallinkfun">Equation&nbsp;<span>3.20</span></a>, <span class="math display">\[
g(\mu) = \mu. \label{eq:canonical.linkfun.normal}
\]</span> Thus the canonical link for the Normal distribution is the identity function.</p>
</section>
<section id="range-of-canonical-link-functions" class="level3" data-number="3.7.3">
<h3 data-number="3.7.3" class="anchored" data-anchor-id="range-of-canonical-link-functions"><span class="header-section-number">3.7.3</span> Range of canonical link functions</h3>
<p>For many models, <span class="math inline">\(\mu\)</span> has a restricted range, but we would like <span class="math inline">\(\eta\)</span> to have unlimited range. It turns out, for several members of the exponential family, that the canonical link function provides <span class="math inline">\(\eta\)</span> with unlimited range. However, Table <a href="#tbl-canonicalrange">Table&nbsp;<span>3.6</span></a> shows that this is not always so.</p>
<div id="tbl-canonicalrange" class="anchored">
<table class="table">
<caption>Table&nbsp;3.6: Canonical link functions and their ranges (see McCullagh and Nelder, 2nd Edn., p291 with <span class="math inline">\(\dagger\)</span>binomial distribution with index <span class="math inline">\(m\)</span> and mean <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\ddagger\)</span>gamma distribution with mean <span class="math inline">\(\mu\)</span> (see Exercises for details).</caption>
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(f(y)\)</span></th>
<th style="text-align: center;">Range of <span class="math inline">\(\mu\)</span></th>
<th style="text-align: center;"><span class="math inline">\(b(\theta)\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\mu=b'(\theta)\)</span></th>
<th style="text-align: center;">Canonical link, <span class="math inline">\(g(\mu)\)</span></th>
<th style="text-align: center;">Range of <span class="math inline">\(\eta\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Normal</td>
<td style="text-align: center;"><span class="math inline">\((-\infty, \infty)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac12 \theta^2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\theta\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\mu\)</span></td>
<td style="text-align: center;"><span class="math inline">\((-\infty, \infty)\)</span></td>
</tr>
<tr class="even">
<td>Poisson</td>
<td style="text-align: center;"><span class="math inline">\((0,\infty)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(e^\theta\)</span></td>
<td style="text-align: center;"><span class="math inline">\(e^\theta\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\log\mu\)</span></td>
<td style="text-align: center;"><span class="math inline">\((-\infty, \infty)\)</span></td>
</tr>
<tr class="odd">
<td>Binomial<span class="math inline">\(\dagger\)</span></td>
<td style="text-align: center;"><span class="math inline">\((0, m)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(m\log(1-e^\theta)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(m/(1+e^{-\theta})\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\mbox{logit}(\mu/m)\)</span></td>
<td style="text-align: center;"><span class="math inline">\((-\infty, \infty)\)</span></td>
</tr>
<tr class="even">
<td>Gamma<span class="math inline">\(\ddagger\)</span></td>
<td style="text-align: center;"><span class="math inline">\((0,\infty)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(-\log (-\theta)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(-\theta^{-1}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(-\mu^{-1}\)</span></td>
<td style="text-align: center;"><span class="math inline">\((-\infty, 0)\)</span></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="sec-canonicallinkconvenience" class="level3" data-number="3.7.4">
<h3 data-number="3.7.4" class="anchored" data-anchor-id="sec-canonicallinkconvenience"><span class="header-section-number">3.7.4</span> Convenience of the canonical link function</h3>
<p>Why is the canonical link function <a href="#eq-canonicallinkfun">Equation&nbsp;<span>3.20</span></a> convenient? The assertion <a href="#eq-G3">Equation&nbsp;<span>3.18</span></a> means that, in the exponential-family formula <a href="#eq-exponential-family">Equation&nbsp;<span>3.3</span></a>, we can simply substitute the linear predictor <span class="math display">\[
\eta=\sum_j \beta_j x_j
\]</span> from <a href="#eq-linpred">Equation&nbsp;<span>3.4</span></a> in place of <span class="math inline">\(\theta\)</span>, to give:</p>
<p><span id="eq-canonicallinkfunf"><span class="math display">\[
    f(y; \mathbf{x}, \boldsymbol{\beta},\phi) = \exp \left\{ \frac{y \left[\sum_j \beta_j x_j\right] - b\left(\left[\sum_j \beta_j x_j\right]\right)}
                                            {\phi} + c(y, \phi) \right\},
\tag{3.22}\]</span></span> where <span class="math inline">\(\mathbf{x}=\{x_{j}, j=1,\dots,p\}\)</span> and <span class="math inline">\(\boldsymbol{\beta}=\{\beta_j, j=1,\dots,p\}\)</span>.</p>
<p>Suppose we have <span class="math inline">\(n\)</span> independent observations, <span class="math inline">\(\{y_i,\ i=1,\ldots,n\}\)</span>. As discussed in Section~<span class="math inline">\(\ref{sect:systematic}\)</span>, the explanatory variables <span class="math inline">\((x_{1},\ldots,x_{p})\)</span> will depend on~<span class="math inline">\(i\)</span>, and so <span class="math inline">\(\eta\)</span> will also depend on~<span class="math inline">\(i\)</span>. Therefore, we attach subscript <span class="math inline">\(i\)</span> to <span class="math inline">\(y\)</span> and to each <span class="math inline">\(x_j\)</span>, giving: <span id="eq-canonicallinkfunf2"><span class="math display">\[
    f(y_i; \{x_{ij}\}, \{\beta_j\}, \phi) =
    \exp \left\{ \frac{y_i \left[\sum_j \beta_j x_{ij}\right] - b\left(\left[\sum_j \beta_j x_{ij}\right]\right)}
                                            {\phi} + c(y_i, \phi) \right\}.
\tag{3.23}\]</span></span> By independence, the joint distribution of all observations <span class="math inline">\(\{y_i\} = \{y_i,\ i=1,\dots,n\}\)</span> is: <span class="math display">\[
f(\mathbf{y}; X, \boldsymbol{\beta},\phi) = \prod_{i=1}^n f(y_i; \theta_i, \phi),
\]</span> so</p>
<p><span class="math display">\[
\log f(\mathbf{y}; X, \boldsymbol{\beta},\phi) =
\sum_{i=1}^n \log f(y_i; \theta_i, \phi)
\]</span> then substituting in <span class="math display">\[
\log f(\mathbf{y}; X, \boldsymbol{\beta},\phi) =
\sum_{i=1}^n
\left\{  \frac{y_i \left[\sum_j \beta_j x_{ij}\right] - b\left(\left[\sum_j \beta_j x_{ij}\right]\right)}{\phi} + c(y_i, \phi)\right\}
\]</span> and finally simplifying to give <span id="eq-canonicallinkfunloglik"><span class="math display">\[
\log f(\mathbf{y}; X, \boldsymbol{\beta},\phi) =
\frac{\sum_j \beta_j S_j - \sum_i b\left(\left[\sum_j \beta_j x_{ij}\right]\right)}
{\phi} + \sum_i c(y_i, \phi)
\tag{3.24}\]</span></span> where <span class="math display">\[
S_j = \sum_{i=1}^n  y_i  x_{ij}.
\]</span> Thus, in the log-likelihood <a href="#eq-canonicallinkfunloglik">Equation&nbsp;<span>3.24</span></a>, it is only the first term that involves both the observations <span class="math inline">\(\mathbf{y}=\{y_i,\ i=1,\dots,n\}\)</span> and the parameters <span class="math inline">\(\boldsymbol{\beta}=\{\beta_j, j=1,\dots,p\}\)</span>, and this term depends on the observations only through the statistics <span class="math inline">\(\mathbf{S}=\{S_j, j=1,\dots,p\}\)</span>. These are called <em>sufficient statistics</em>, and their appearance in <a href="#eq-canonicallinkfunloglik">Equation&nbsp;<span>3.24</span></a> confers both theoretical and practical advantages.</p>
</section>
</section>
<section id="sec-mle" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="sec-mle"><span class="header-section-number">3.8</span> Maximum likelihood estimation for generalized linear models</h2>
<p>Throughout this module we use the principle of maximum likelihood estimation (MLE) to estimate regression parameters.</p>
<section id="sec-mle.iid" class="level3" data-number="3.8.1">
<h3 data-number="3.8.1" class="anchored" data-anchor-id="sec-mle.iid"><span class="header-section-number">3.8.1</span> The i.i.d. case</h3>
<p>Suppose we have <span class="math inline">\(n\)</span> i.i.d. observations <span class="math inline">\(\{y_i,\ i=1,\ldots,n\}\)</span>, where each <span class="math inline">\(y_i\)</span> is sampled from the same exponential family density <a href="#eq-exponential-family">Equation&nbsp;<span>3.3</span></a> <span id="eq-iidobs"><span class="math display">\[
f(y_i; \theta,\phi) = \exp \left\{ \frac{\theta y_i - b(\theta)}{\phi} + c(y_i, \phi) \right\}.
\tag{3.25}\]</span></span> For simplicity we assume the canonical parameter <span class="math inline">\(\theta\)</span> does not depend on <span class="math inline">\(i\)</span>. Later, we will consider the case where <span class="math inline">\(\theta\)</span> depends on <span class="math inline">\(i\)</span> through covariates <span class="math inline">\(\{x_{ij},\ j=1,\dots,p\}\)</span>, as in Section <a href="#sec-canonicallinkconvenience"><span>Section&nbsp;3.7.4</span></a>.</p>
<p>By independence, the joint distribution of all the observations <span class="math inline">\(\{y_i\} = \{y_i,\ i=1,\dots,n\}\)</span> is: <span class="math display">\[
f(\{y_i\}; \theta,\phi) = \prod_{i=1}^n f(y_i; \theta, \phi).
\]</span> So <span class="math display">\[
\log f(\{y_i\}; \theta,\phi) = \sum_{i=1}^n \log f(y_i; \theta, \phi)
= \sum_{i=1}^n \left[\frac{\theta y_i - b(\theta)}{\phi} + c(y_i, \phi)\right].
\]</span> Regarding the observations <span class="math inline">\(\{y_i\}\)</span> as constants (which they are, once we have them) and the scale parameter <span class="math inline">\(\phi\)</span> as a fixed <em>nuisance</em> parameter (whose value we may not know), the log-likelihood as a function of the parameter <span class="math inline">\(\theta\)</span> of interest is: <span id="eq-ltheta"><span class="math display">\[
l(\theta; \{y_i\},\phi)  = n\ \frac{\theta \bar{y} -  b(\theta)}{\phi} + \mbox{constant},
\tag{3.26}\]</span></span> where <span class="math inline">\(\bar{y}= \frac{1}{n} \sum_{i=1}^n y_i\)</span>.</p>
<p>We estimate <span class="math inline">\(\theta\)</span> by maximizing the log likelihood – i.e.&nbsp;given the data <span class="math inline">\(\{y_i,\ i=1,\dots,n\}\)</span>, we estimate the value of <span class="math inline">\(\theta\)</span> to be that value for which the likelihood, and hence the log-likelihood, is greatest.</p>
<p>We maximize the log-likelihood by differentiating it and setting it to zero: <span class="math display">\[
\frac{d l(\theta; \{y_i\},\phi)}{d \theta}  = n\ \frac{\bar{y} -  b'(\theta)}{\phi}
\]</span> and hence the MLE for <span class="math inline">\(\theta\)</span>, which we denote <span class="math inline">\(\hat\theta\)</span>, satisfies <span id="eq-exponentialfamilybary"><span class="math display">\[
b'(\hat\theta) = \bar{y}.
\tag{3.27}\]</span></span> Now, we showed in <a href="#prp-moments">Proposition&nbsp;<span>3.1</span></a> that <span class="math display">\[
\mbox{E}[Y] = \mu =b'(\theta).
\]</span> Let <span class="math inline">\(\hat\mu\)</span> denote the MLE of <span class="math inline">\(\mu\)</span>. Then <span class="math display">\[
\hat\mu = b'(\hat{\theta}),
\]</span> because the MLE of any function <span class="math inline">\(\zeta = h(\theta)\)</span> of the parameters is <span class="math inline">\(\hat{\zeta} = h(\hat{\theta})\)</span>. Therefore, we have <span id="eq-exponentialfamilymuhat"><span class="math display">\[
\hat\mu = \bar{y}.
\tag{3.28}\]</span></span> So we find that <span class="math inline">\(\hat\theta\)</span> is the value of <span class="math inline">\(\theta\)</span> for which the theoretical mean <span class="math inline">\(\hat\mu = b'(\hat\theta)\)</span> matches the sample mean <span class="math inline">\(\bar{y}\)</span>.</p>
</section>
<section id="accuracy-of-mles-in-the-i.i.d.-case" class="level3" data-number="3.8.2">
<h3 data-number="3.8.2" class="anchored" data-anchor-id="accuracy-of-mles-in-the-i.i.d.-case"><span class="header-section-number">3.8.2</span> Accuracy of MLEs in the i.i.d. case</h3>
<p>For our i.i.d. sample <span class="math inline">\(\{y_i,\ i=1,\ldots,n\}\)</span>, we have <span class="math inline">\(b'(\hat\theta) = \hat\mu = \bar y\)</span>. Let <span class="math inline">\(\theta_0\)</span> be the true value of <span class="math inline">\(\theta\)</span> with corresponding mean <span class="math inline">\(\mu_0\)</span>, i.e. <span id="eq-mu0"><span class="math display">\[
b'(\theta_0) = \mu_0.  
\tag{3.29}\]</span></span> How accurate is <span class="math inline">\(\hat\theta\)</span>? We know that <span id="eq-Ebary"><span class="math display">\[
\mbox{E}[\bar Y] = \mbox{E}\left(\frac{1}{n}\sum_{i=1}^n y_i\right)
= \frac{1}{n} \sum_{i=1}^n \mbox{E}(y_i)
= \mu_0  
= b'(\theta_0),
\tag{3.30}\]</span></span> using <a href="#eq-mu0">Equation&nbsp;<span>3.29</span></a>, and <span class="math display">\[
\mbox{Var}[\bar Y] = \mbox{Var}\left(\frac{1}{n} \sum_{i=1}^n y_i\right)
= \frac{1}{n^2}  \sum_{i=1}^n \mbox{Var}(y_i)
\]</span> because the observations are independent, <span id="eq-varbary"><span class="math display">\[
= \frac{1}{n} \ b''(\theta_0) \phi,
\tag{3.31}\]</span></span> using the result <a href="#eq-exponential-moments">Equation&nbsp;<span>3.8</span></a>.</p>
<p>We can use Taylor’s theorem to expand <span class="math inline">\(b'(\hat\theta)\)</span> about <span class="math inline">\(\theta_0\)</span>: <span class="math display">\[
\bar y = b'(\hat\theta) \approx  b'(\theta_0) + (\hat\theta - \theta_0) b''(\theta_0),
\]</span> which implies that <span id="eq-hattheta-theta0"><span class="math display">\[
(\hat\theta - \theta_0) \approx  b''(\theta_0)^{-1}\{b'(\hat\theta) - b'(\theta_0)\}  
= b''(\theta_0)^{-1}(\bar y - \mu_0),
\tag{3.32}\]</span></span> using <a href="#eq-exponentialfamilybary">Equation&nbsp;<span>3.27</span></a> and <a href="#eq-mu0">Equation&nbsp;<span>3.29</span></a>. We can use <a href="#eq-hattheta-theta0">Equation&nbsp;<span>3.32</span></a> to get approximations to the mean and variance of <span class="math inline">\(\hat\theta\)</span>:} <span class="math display">\[
\mbox{E}[\hat\theta - \theta_0]  \approx   b''(\theta_0)^{-1} \mbox{E}(\bar y - \mu_0)  
= 0,
\]</span> using <a href="#eq-Ebary">Equation&nbsp;<span>3.30</span></a>, so <span id="eq-Ehattheta"><span class="math display">\[
\mbox{E}(\hat\theta) \approx \theta_0,
\tag{3.33}\]</span></span> and <span class="math display">\[
\mbox{Var}(\hat\theta) \approx \mbox{E}\left[(\hat\theta - \theta_0)^2\right]
\]</span> using <a href="#eq-Ehattheta">Equation&nbsp;<span>3.33</span></a>, <span class="math display">\[
\mbox{Var}(\hat\theta) \approx \mbox{E}\left[\left(b''(\theta_0)^{-1}(\bar y - \mu_0)\right)^2\right]
\]</span> using <a href="#eq-hattheta-theta0">Equation&nbsp;<span>3.32</span></a>, <span class="math display">\[
\mbox{Var}(\hat\theta)\approx  \left(b''(\theta_0)\right)^{-2} \mbox{Var}[(\bar Y)]  
\]</span> using <a href="#eq-Ebary">Equation&nbsp;<span>3.30</span></a>, <span id="eq-Varhattheta"><span class="math display">\[
\mbox{Var}(\hat\theta) = \frac{\phi}{n \ b''(\theta_0)}
\tag{3.34}\]</span></span> using <a href="#eq-varbary">Equation&nbsp;<span>3.31</span></a>.</p>
<p>Thus we see that the first two derivatives of <span class="math inline">\(b(\theta)\)</span> play a key role in inference.</p>
</section>
</section>
<section id="exercises" class="level2" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="exercises"><span class="header-section-number">3.9</span> Exercises</h2>
<p>3.1 In the binomial distribution, show that <span class="math inline">\(-m\log(1-p)=m\log(1+e^\theta)\)</span> where <span class="math inline">\(\theta=\mbox{logit }p\)</span>.</p>
<p>3.2 Use the results in <a href="#sec-exponential-family"><span>Section&nbsp;3.4</span></a> and the exponential family description of the Binomial distribution in <a href="#sec-exponential-binomial"><span>Section&nbsp;3.3.2</span></a> to show that the mean and variance of a <span class="math inline">\(\text{Bin}(m,p)\)</span> are <span class="math inline">\(mp\)</span> and <span class="math inline">\(mp(1-p)\)</span>.</p>
<p><em>Hint: <span class="math inline">\(f'(g(x)) = f'(g(x)) g'(x)\)</span></em></p>


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Dobson and Barnett, 3rd edn, Table 1.2<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./2_linearmodels.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Essentials of Gaussian Linear Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./4_GLM-Fitting.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">GLM fitting</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>
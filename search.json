[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MATH3823 Generalized Linear Models",
    "section": "",
    "text": "\\[\n\\def\\b#1{\\mathbf{#1}}\n\\]\n\n\nWeekly schedule\n\n\n\n\n\n\nImportant\n\n\n\nOur regular class times are:\n           Tuesday 11-12, Roger Stevens, LT25\n           Thursday 2-3, Roger Stevens, LT23\n\n\n\n\n\n\n\n\nWeek 1 (30 January - 3 February)\n\n\n\n\nBefore next Lecture: Please read the Preface.\nLecture on Tuesday: We will briefly cover all material in Chapter 1: Introduction.\nBefore next Lecture: Please re-read Chapter 1 carefully.\nLecture on Thursday: Start Chapter 2: Essentials of Normal Linear Models.\nWeekly feedback: Self-study the Exercises in Section 1.5 – solutions to be posted during Week 1.\n\n\n\n\n\n\n\n\n\nWeek 2 (6 - 10 February)\n\n\n\n\nDetails will be added during Week 1.\n\n\n\n\n\n\n\n\n\nCoursework Practical Sessions (20 - 24 March)\n\n\n\n\nDetails to follow in early March."
  },
  {
    "objectID": "0_preface.html",
    "href": "0_preface.html",
    "title": "Preface",
    "section": "",
    "text": "These lecture notes are produced for the University of Leeds module MATH3823 - Generalized Linear Models for the academic year 2022-23. Please note that this material also forms part of the module MATH5824 - Generalized Linear and Additive Models. They are based on those used previously for this module and I am grateful to previous module lecturers for their considerable effort: Lanpeng Ji, Amanda Minter, John Kent, Wally Gilks, and Stuart Barber. This is the first year, however, that they have been produced in accessible format and hence some errors might occur during this conversion process. For information, I am using Quarto (a successor to RMarkdown) from RStudio to produce both the html and PDF, and then GitHub to create the website which can be accessed at rgaykroyd.github.io/MATH3823/. Please note that the PDF versions will only be made available on the University of Leeds Minerva system. Although I am a long-term user of RStudio, I have not previously used Quarto/RMarkdown nor Github and hence please be patient if there are hitches along the way.\nRG Aykroyd, Leeds, November 22, 2022\n\n\n\n\n\n\n\n\nWarning\n\n\n\nStatistical ethics and sensitive data\nPlease note that from time to time we will be using data sets from situations which some might perceive as sensitive. All such data sets will, however, be derived from real-world studies which appear in textbooks or in scientific journals. The daily work of many statisticians involves applying their professional skills in a wide variety of situations and as such it is important to include a range of commonly encountered examples in this module. Whenever possible, sensitive topics will be signposted in advance. If you feel that any examples may be personally upsetting then, if possible, please contact the module lecturer in advance. If you are significantly effected by any of these situations, then you can seek support from the Student Counselling and Wellbeing service."
  },
  {
    "objectID": "1_intro.html#overview",
    "href": "1_intro.html#overview",
    "title": "1  Introduction",
    "section": "1.1 Overview",
    "text": "1.1 Overview\nIn previous modules you have studied linear models with a normally distributed error term, such as simple linear regression, multiple linear regression and ANOVA for normally distributed observations. In this module we will study generalized linear models.\nOutline of the module:\n\nRevision of linear models with normal errors.\nIntroduction to generalized linear models, GLMs.\nLogistic regression models.\nLoglinear models, including contingency tables.\n\n\n\n\n\n\n\nImportant\n\n\n\nThis module will make extensive use of \\(\\mathbf{R}\\) and hence it is very important that you are comfortable with its use. If you need some revision, then material is available on Minerva under RStudio Support.\n\n\nThe purpose of a generalized linear model is to describe the dependence of a response variable \\(y\\) on a set of \\(p\\) explanatory variables \\(\\b{x}=(x_1, x_2, \\ldots, x_p)\\) where, conditionally on \\(\\b{x}\\), observation \\(y\\) has a distribution which is not necessarily normal.\nNote that in these notes we may use lowercase letters, for example \\(y\\) or \\(y_i,\\) to denote both observed values or random variables, which is being considered should be clear from the context.\n\n\n\n\n\n\nImportant\n\n\n\nThis module will make extensive use of many basic ideas from statistics. If you need some revision, then see Appendix A: Basic material on Minerva under Basic Pre-requisite Material."
  },
  {
    "objectID": "1_intro.html#motivating-example",
    "href": "1_intro.html#motivating-example",
    "title": "1  Introduction",
    "section": "1.2 Motivating example",
    "text": "1.2 Motivating example\nTable 1.1 shows data1 on the number of beetles killed by five hours of exposure to 8 different concentrations of gaseous carbon disulphide.\n\n\nTable 1.1: Numbers of beetles killed by five hours of exposure to 8 different concentrations of gaseous carbon disulphide\n\n\n\n\n\n\n\nDose\n\\(x_i\\)\nNo. of beetle\n\\(m_i\\)\nNo. killed\n\\(y_i\\)\n\n\n\n\n1.6907\n59\n6\n\n\n1.7242\n60\n13\n\n\n1.7552\n62\n18\n\n\n1.7842\n56\n28\n\n\n1.8113\n63\n52\n\n\n1.8369\n59\n53\n\n\n1.8610\n62\n61\n\n\n1.8839\n60\n60\n\n\n\n\nFigure 1.1 (a) shows the same data with a linear regression line superimposed. Although this line goes close to the plotted points, we can see some fluctuations around it. More seriously, this is a stupid model: it would predict a mortality rate of greater than 100% at a dose of 1.9 units, and a negative mortality rate at 1.65 units!\n\n\nCode\nbeetle = read.table(\"https://rgaykroyd.github.io/MATH3823/Datasets/beetle.txt\", header=T)\n\ndose = beetle$dose\nmortality = beetle$died/beetle$total\n\nplot(dose, mortality, pch=16,\n     xlim=c(1.65, 1.90), xlab =\"Dose\",\n     ylim=c(-0.1, 1.1),  ylab=\"Mortality\")\nabline(h=c(0,1), lty=2)\n\nlm.fit = lm(mortality ~ dose)\nabline(lm.fit)\n\nplot(dose, mortality, pch=16,\n     xlim=c(1.65, 1.90), xlab =\"Dose\",\n     ylim=c(-0.1, 1.1),  ylab=\"Mortality\")\nabline(h=c(0,1), lty=2)\n\ny = cbind(beetle$died, beetle$total-beetle$died)\nglm.fit = glm(y ~ dose, family=binomial(link='logit'))\n\noutput.dose = seq(1.6,1.95,0.001)\nfitted = predict(glm.fit, data.frame(dose=output.dose), type=\"response\")\nlines(output.dose, fitted)\n\n\n\n\n\n\n\n\n(a) Linear model\n\n\n\n\n\n\n\n(b) Logistic model\n\n\n\n\nFigure 1.1: Beetle mortality rates with fitted dose- response curves.\n\n\n\nA more sensible dose–response relationship for the beetle mortality data might be based on the logistic function (to be defined later), as plotted in Figure 1.1 (b). The resulting curve is a closer, more-sensible, fit. Later in this module we will see how this curve was fitted using maximum likelihood estimation for an appropriate generalized linear model.\nThis is an example of a dose-response experiment which are widely used in medical and pharmaceutical situations.\n\n\n\n\n\n\nWarning\n\n\n\nWarning of potentially sensitive material. For further information on dose-response experiments see, for example, www.britannica.com/science/dose-response-relationship."
  },
  {
    "objectID": "1_intro.html#revision-of-least-squares-estimation",
    "href": "1_intro.html#revision-of-least-squares-estimation",
    "title": "1  Introduction",
    "section": "1.3 Revision of least-squares estimation",
    "text": "1.3 Revision of least-squares estimation\nSuppose that we have \\(n\\) paired data values \\((x_1, y_1),\\dots, (x_n, y_n)\\) and that we believe these are related by a linear model\n\\[\nY_i = \\alpha+\\beta x_i +\\epsilon_i\n\\]\nfor all \\(i\\in \\{1, 2,\\dots,n\\}\\), where \\(\\epsilon_1,\\dots,\\epsilon_n\\) are independent and identically distributed (iid) with \\(\\mbox{E}(\\epsilon_i)=0\\) and \\(\\mbox{Var}(\\epsilon_i)=\\sigma^2\\). The aim will be to find values of the model parameters, \\(\\alpha, \\beta \\text{ and } \\sigma^2\\) using the data. Specifically, we will estimate \\(\\alpha\\) and \\(\\beta\\) using the values which minimize the residual sum of squares (RSS)\n\\[\nRSS(\\alpha, \\beta) = \\sum_{i=1}^n \\left(y_i-(\\alpha+\\beta x_i)\\right)^2.\n\\tag{1.1}\\]\nThis measures how close the data points are around the regression line and hence the resulting estimates, \\(\\hat\\alpha\\) and \\(\\hat\\beta\\), will give us a fitted regression line which is closest to the data.\nIt can be shown that Equation 1.1 takes its minimum when the parameters are given by\n\\[\n\\hat\\alpha = \\bar y -\\hat\\beta\\bar x, \\quad \\mbox{and} \\quad\n\\hat\\beta = \\frac{s_{xy}}{s^2_x}\n\\tag{1.2}\\]\nwhere \\(\\bar x\\) and \\(\\bar y\\) are the sample means,\n\\[\ns_{xy}=\\frac{1}{n-1}\\sum_{i=1}^n (x_i-\\bar x)(y_i-\\bar y)\n\\]\nis the sample covariance and\n\\[\ns^2_x = \\frac{1}{n-1} \\sum_{i=1}^n (x_i-\\bar x)^2\n\\]\nis the sample variance of the \\(x\\) values. It can be shown that these estimators are unbiased, that is \\(\\mbox{E}[\\hat\\alpha]=\\alpha\\) and \\(\\mbox{E}[\\hat\\beta]=\\beta\\) – see Section 1.5.\nThe fitted regression lines is then given by \\(\\hat y = \\hat \\alpha +\\hat \\beta x\\), the fitted values by \\(\\hat y_i = \\hat \\alpha +\\hat \\beta x_i\\), and the model residuals by \\(r_i= \\hat \\epsilon_i= y_i-\\hat y_i\\) for all \\(i\\in \\{1,\\dots,n\\}\\).\nTo complete the model fitting, we also estimate the error variance, \\(\\sigma^2\\), using \\[\n\\hat \\sigma^2 = \\frac{1}{n-2} \\sum _{i=1}^n r_i^2.\n\\tag{1.3}\\]\nNote that, by construction, \\(\\bar r=0\\) and, further, it can be shown that \\(\\hat \\sigma^2\\) is an unbiased estimator of \\(\\sigma^2\\), that is \\(\\mbox{E}[\\hat\\sigma^2]=\\sigma^2\\).\n\n\nCode\nxbar = mean(dose)\nybar = mean(mortality)\ns2x = var(dose)\nsxy = cov(dose, mortality)\n\nbetahat = sxy/s2x\nalphahat = ybar-betahat*xbar\n\ns2hat = sum((mortality-alphahat-betahat*dose)^2)/(length(dose)-2)\n\n\nReturning to the above beetle data example, we have \\(\\hat\\alpha=\\)-8.947843, \\(\\hat\\beta=\\) 5.324937, and \\(\\hat \\sigma^2 =\\) 0.0075151.\nWe will interpret the output later, but in \\(\\b{R}\\), the fitting can be done with a single command with corresponding fitting output from a second command:\n\n\nCode\nlm.fit = lm(mortality ~ dose)\n\nsummary(lm.fit)\n\n\n\nCall:\nlm(formula = mortality ~ dose)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.10816 -0.06063  0.00263  0.05119  0.12818 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -8.9478     0.8717  -10.27 4.99e-05 ***\ndose          5.3249     0.4857   10.96 3.42e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.08669 on 6 degrees of freedom\nMultiple R-squared:  0.9524,    Adjusted R-squared:  0.9445 \nF-statistic: 120.2 on 1 and 6 DF,  p-value: 3.422e-05\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou should have met \\(\\b{R}\\) output like this in previous statistics modules, but if you need some revision then see Appendix-C: Background to Analysis of Variance on Minerva under Basic Pre-requisite Material."
  },
  {
    "objectID": "1_intro.html#types-of-variables",
    "href": "1_intro.html#types-of-variables",
    "title": "1  Introduction",
    "section": "1.4 Types of variables",
    "text": "1.4 Types of variables\nThe way a variable enters a model will depends on its type. The most common five types of variable are:\n\nQuantitative\n\nContinuous: for example, height; weight; duration. Real valued. Note that although recorded data is rounded it is still usually best regarded as continuous.\nCount (discrete): for example, number of children in a family; accidents at a road junction; number of items sold. Non-negative and integer-valued.\n\nQualitative\n\nOrdered categorical (ordinal): for example, severity of illness (Mild/ Moderate/Severe); degree classification (first/ upper-second/ lower-second/ third).\nUnordered categorical (nominal):\n\nDichotomous (binary): two categories: for example sex (M/ F); agreement (Yes/ No); coin toss (Head/ Tail).\nPolytomous2: more than two categories: for example blood group (A/ B/ O); eye colour (Brown/ Blue/ Green).\n\n\n\nNote that although dichotomous is clearly a special case of polytomous, making the distinction is usually worthwhile as it often leads to a simplified modelling and testing approach."
  },
  {
    "objectID": "1_intro.html#sec-exercises1",
    "href": "1_intro.html#sec-exercises1",
    "title": "1  Introduction",
    "section": "1.5 Exercises",
    "text": "1.5 Exercises\n\n1.1 Consider again the beetle data in Table 1.1. Perform the calculations by hand and then check the answers using \\(\\b{R}\\) – a copy of the data is available at: rgaykroyd.github.io/Datasets/beetle.txt. Finally plot the fitted regression line on a scatter plot of the data. [Hint: See the code chunk used to produce Figure 1.1.]\n1.2 Consider the following synthetic data:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(i=1\\)\n\\(i=2\\)\n\\(i=3\\)\n\\(i=4\\)\n\\(i=5\\)\n\\(i=6\\)\n\\(i=7\\)\n\\(i=8\\)\n\n\n\n\n\\(x_i\\)\n-1\n0\n1\n2\n2.5\n3\n4\n6\n\n\n\\(y_i\\)\n-2.8\n-1.1\n7.2\n8.0\n8.9\n9.2\n14.8\n24.7\n\n\n\nPlot the data to check that a linear model is suitable and then fit a linear regression model. Do you think that the fitted model can be reliably used to predict the values of \\(y\\) when \\(x=5\\) and \\(x=10\\)? Justify your answers.\n1.3 Starting from Equation 1.1, derive the estimation equations given in Equation 1.2. Further, show that \\(\\hat\\alpha\\) and \\(\\hat\\beta\\) are unbiased estimators of \\(\\alpha\\) and \\(\\beta\\). [Hint: Check your MATH1712 lecture notes.]\nWhat can be said about \\(\\hat\\sigma^2\\) as an estimator of \\(\\sigma^2\\)? [Hint: There is a careful theoretical proof, please have a go, but here a descriptive explanation is OK.]\n1.4 The Brownlee’s Stack Loss Plant Data3 is already available in \\(\\mathbf{R}\\), with background details on the help page, \\(\\texttt{?stackloss}\\). [Hint: You already met this example in MATH1712.]\nAfter plotting all pairs of variables, which of \\(\\texttt{Air.Flow}\\), \\(\\texttt{Water.Temp}\\) and \\(\\texttt{Acid.Conc}\\) do you think could be used to model \\(\\texttt{stack.loss}\\) using a linear regression? Justify your answer.\nPerform a simple linear regression with using \\(\\texttt{stack.loss}\\) as the response variable and your chosen variable as the explanatory variable. Add the fitted regression line to a scatter plot of the data and comment.\n1.5 In an experiment conducted by de Silva et al. in 20204 data was obtained to investigate falling objects and gravity, as first consider by Galileo and Newton. A copy of the data is available in the file: physics_from_data.csv\nRead the data file into \\(\\b{R}\\) and perform a simple linear regression of the maximum Reynolds number as the response variable and, in turn, each of the other variables as the explanatory variable.\nPlot the data and add the corresponding fitted linear models. Which variable do you think helps explain Reynolds number the best? Why do you think this?\n\n\nHere are an infinite number of further numerical examples from maths e.g. (thanks to https://www.mathcentre.ac.uk/):\nFinding the intersercept\nFinding the slope - Part 1\nFinding the slope - Part 2"
  }
]